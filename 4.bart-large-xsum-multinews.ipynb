{"metadata":{"colab":{"name":"Bart_large_xsum_fine_tuned_samsum.ipynb","provenance":[],"mount_file_id":"1ne8zLt24E5F0_dHBMvPmGZgvLc4kj1yx","authorship_tag":"ABX9TyMJwk0rj9PDk0qfY2nIIxi9","include_colab_link":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1155d59c55414b8eb319b8359de0cb51":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_439edcd111c74f4e8b023aad54ff614c","IPY_MODEL_f662b47242024f55ab82c83e40cd44a8","IPY_MODEL_1b6ed7ecce8a410fb123348716e325bd"],"layout":"IPY_MODEL_edd0d9b6f6b742b1ba86e9f8d0d6222f"}},"439edcd111c74f4e8b023aad54ff614c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c43e6f76260b4decad996a2ca3198102","placeholder":"​","style":"IPY_MODEL_f23550c830464f888aec19a60622ce3d","value":"100%"}},"f662b47242024f55ab82c83e40cd44a8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_94b27a449be04eaeb84605961610ddb1","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7a09725f31584bef97bba6f29856b82f","value":1}},"1b6ed7ecce8a410fb123348716e325bd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf7750858e074552a6efcf646cd13ae7","placeholder":"​","style":"IPY_MODEL_341a7cd4f32449188c714c82c29f27c2","value":" 1/1 [00:00&lt;00:00,  1.78ba/s]"}},"edd0d9b6f6b742b1ba86e9f8d0d6222f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c43e6f76260b4decad996a2ca3198102":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f23550c830464f888aec19a60622ce3d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"94b27a449be04eaeb84605961610ddb1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a09725f31584bef97bba6f29856b82f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bf7750858e074552a6efcf646cd13ae7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"341a7cd4f32449188c714c82c29f27c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"01315fd3d21d40f694a77c1292d5c48d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6d4d6b64f5a04621b2eb89fed98bb24d","IPY_MODEL_8056e2ea2a7c42ef873aa8c028b696d3","IPY_MODEL_43686ff3741c4fc8ab51a8ad2fe4664d"],"layout":"IPY_MODEL_bfe627cda8d84d70865f40b8e043289b"}},"6d4d6b64f5a04621b2eb89fed98bb24d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bdb01bd649024ef9aef1ad6c716fcad4","placeholder":"​","style":"IPY_MODEL_552cebef4aab4cf29fac95a1ef7910d2","value":"Downloading: 100%"}},"8056e2ea2a7c42ef873aa8c028b696d3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a09d4e3213304039994ed974314044bb","max":1625270765,"min":0,"orientation":"horizontal","style":"IPY_MODEL_135737bcc62f438d9688be0e885ac291","value":1625270765}},"43686ff3741c4fc8ab51a8ad2fe4664d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1fd7cd00c9df4e67b18365d3df3eaf0d","placeholder":"​","style":"IPY_MODEL_b2438fa7aa154da689234264304e3686","value":" 1.51G/1.51G [00:50&lt;00:00, 28.2MB/s]"}},"bfe627cda8d84d70865f40b8e043289b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bdb01bd649024ef9aef1ad6c716fcad4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"552cebef4aab4cf29fac95a1ef7910d2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a09d4e3213304039994ed974314044bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"135737bcc62f438d9688be0e885ac291":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1fd7cd00c9df4e67b18365d3df3eaf0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2438fa7aa154da689234264304e3686":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Install necessary packages","metadata":{"id":"Vkdphio1MyfM"}},{"cell_type":"code","source":"!pip install transformers datasets ","metadata":{"id":"6It5FQ_JXVFg","execution":{"iopub.status.busy":"2022-11-21T16:56:09.825330Z","iopub.execute_input":"2022-11-21T16:56:09.825802Z","iopub.status.idle":"2022-11-21T16:56:21.969975Z","shell.execute_reply.started":"2022-11-21T16:56:09.825719Z","shell.execute_reply":"2022-11-21T16:56:21.968416Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.20.1)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (2.1.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.13.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.7.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.1)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2022.8.2)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.1)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets) (3.0.0)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.3.5)\nRequirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.5.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.13)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (5.0.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (21.4.0)\nRequirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.1.1)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.7.2)\nRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (2.1.0)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.9.24)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.12)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2022.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install rouge.score nltk py7zr","metadata":{"id":"fu4TlYGFHvW9","execution":{"iopub.status.busy":"2022-11-21T16:56:21.973424Z","iopub.execute_input":"2022-11-21T16:56:21.974144Z","iopub.status.idle":"2022-11-21T16:56:36.139699Z","shell.execute_reply.started":"2022-11-21T16:56:21.974106Z","shell.execute_reply":"2022-11-21T16:56:36.138495Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting rouge.score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (3.7)\nCollecting py7zr\n  Downloading py7zr-0.20.2-py3-none-any.whl (65 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m774.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.7/site-packages (from rouge.score) (0.15.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from rouge.score) (1.21.6)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from rouge.score) (1.15.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk) (8.0.4)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk) (1.0.1)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.7/site-packages (from nltk) (2021.11.10)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from nltk) (4.64.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from py7zr) (5.9.1)\nCollecting pycryptodomex>=3.6.6\n  Downloading pycryptodomex-3.15.0-cp35-abi3-manylinux2010_x86_64.whl (2.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting multivolumefile>=0.2.3\n  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\nCollecting pybcj>=0.6.0\n  Downloading pybcj-1.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pyzstd>=0.14.4\n  Downloading pyzstd-0.15.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (379 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m379.2/379.2 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pyppmd<1.1.0,>=0.18.1\n  Downloading pyppmd-1.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.6/138.6 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting inflate64>=0.3.1\n  Downloading inflate64-0.3.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.6/93.6 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting brotli>=1.0.9\n  Downloading Brotli-1.0.9-cp37-cp37m-manylinux1_x86_64.whl (357 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m357.2/357.2 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from py7zr) (4.13.0)\nRequirement already satisfied: texttable in /opt/conda/lib/python3.7/site-packages (from py7zr) (1.6.4)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->py7zr) (3.8.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->py7zr) (4.1.1)\nBuilding wheels for collected packages: rouge.score\n  Building wheel for rouge.score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge.score: filename=rouge_score-0.1.2-py3-none-any.whl size=24955 sha256=4d859715c58fc0608012f6f7a44a4dd8f152ab8d3299e14791e5334c4441c6bb\n  Stored in directory: /root/.cache/pip/wheels/84/ac/6b/38096e3c5bf1dc87911e3585875e21a3ac610348e740409c76\nSuccessfully built rouge.score\nInstalling collected packages: brotli, pyzstd, pyppmd, pycryptodomex, multivolumefile, pybcj, inflate64, py7zr, rouge.score\nSuccessfully installed brotli-1.0.9 inflate64-0.3.1 multivolumefile-0.2.3 py7zr-0.20.2 pybcj-1.0.1 pycryptodomex-3.15.0 pyppmd-1.0.0 pyzstd-0.15.3 rouge.score-0.1.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# Fine tune with transformers","metadata":{"id":"snDlR92_HwvU"}},{"cell_type":"code","source":"import transformers\nfrom datasets import load_dataset, load_metric, load_from_disk\nimport numpy as np\nimport nltk\nnltk.download('punkt')","metadata":{"id":"tYepXHS0Hva7","colab":{"base_uri":"https://localhost:8080/"},"outputId":"dfb8daf6-a872-411a-d806-a5e0ff77d669","execution":{"iopub.status.busy":"2022-11-21T16:56:36.141736Z","iopub.execute_input":"2022-11-21T16:56:36.142199Z","iopub.status.idle":"2022-11-21T16:56:38.073688Z","shell.execute_reply.started":"2022-11-21T16:56:36.142154Z","shell.execute_reply":"2022-11-21T16:56:38.072684Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","source":"## Loading dataset error\n\nSometimes when loading the dataset wile in GPU enviorment it will give the error that it cannot find the *samsum* dataset. The workaround is to load the dataset while in CPU mode then save it localy or on you drive. After that just switch back to GPU and load the dataset from the local file using *load_from_disk()*","metadata":{"id":"AmUOv29OKEdH"}},{"cell_type":"code","source":"data = load_dataset('multi_news')\n#data.save_to_disk('/content/samsum')\n#data = load_from_disk(\"/content/drive/MyDrive/samsum\")\nmetric = load_metric('rouge')\nmodel_checkpoints = 'facebook/bart-large-xsum'","metadata":{"id":"31ijZrafHveJ","execution":{"iopub.status.busy":"2022-11-21T16:56:38.076449Z","iopub.execute_input":"2022-11-21T16:56:38.077867Z","iopub.status.idle":"2022-11-21T16:57:01.084141Z","shell.execute_reply.started":"2022-11-21T16:56:38.077827Z","shell.execute_reply":"2022-11-21T16:57:01.083265Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/1.61k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb116dfebb9043689604219e93abaa39"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/932 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05e57ef29ab14500ba74da4a6658ba86"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset multi_news/default (download: 245.06 MiB, generated: 667.72 MiB, post-processed: Unknown size, total: 912.78 MiB) to /root/.cache/huggingface/datasets/multi_news/default/1.0.0/2e145a8e21361ba4ee46fef70640ab946a3e8d425002f104d2cda99a9efca376...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/257M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6388c3dc54f43499040f10df5beca39"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/44972 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/5622 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/5622 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset multi_news downloaded and prepared to /root/.cache/huggingface/datasets/multi_news/default/1.0.0/2e145a8e21361ba4ee46fef70640ab946a3e8d425002f104d2cda99a9efca376. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2839e716fd264384a40b84f1f00aaecb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.16k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5635daa022384efe856c9e404145d0ca"}},"metadata":{}}]},{"cell_type":"markdown","source":"## Data tokenization\n\n**max_input** and **max_target** can variy depending on the available computing power","metadata":{"id":"guZ_e3gNLTjd"}},{"cell_type":"code","source":"max_input = 512\nmax_target = 128\ntokenizer = transformers.AutoTokenizer.from_pretrained(model_checkpoints)","metadata":{"id":"ogmXI5cKn_jG","execution":{"iopub.status.busy":"2022-11-21T16:57:01.086632Z","iopub.execute_input":"2022-11-21T16:57:01.087239Z","iopub.status.idle":"2022-11-21T16:57:07.738851Z","shell.execute_reply.started":"2022-11-21T16:57:01.087199Z","shell.execute_reply":"2022-11-21T16:57:07.737807Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e002a4b30af4d62aeb36909098d38cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.48k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd8ab8487bb6460386186cff4afda170"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"845f877dccfe4c36850e6548eeed313d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1abd5b8ae5c84c97a96c250c4b6c26a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2080bda84175430596509ae2e0524ca5"}},"metadata":{}}]},{"cell_type":"code","source":"def preprocess_data(data_to_process):\n  #get the dialogue text\n  inputs = [dialogue for dialogue in data_to_process['document']]\n  #tokenize text\n  model_inputs = tokenizer(inputs,  max_length=max_input, padding='max_length', truncation=True)\n\n  #tokenize labels\n  with tokenizer.as_target_tokenizer():\n    targets = tokenizer(data_to_process['summary'], max_length=max_target, padding='max_length', truncation=True)\n    \n  model_inputs['labels'] = targets['input_ids']\n  #reuturns input_ids, attention_masks, labels\n  return model_inputs","metadata":{"id":"R0iO80XDn_nE","execution":{"iopub.status.busy":"2022-11-21T16:57:07.740398Z","iopub.execute_input":"2022-11-21T16:57:07.740773Z","iopub.status.idle":"2022-11-21T16:57:07.747259Z","shell.execute_reply.started":"2022-11-21T16:57:07.740735Z","shell.execute_reply":"2022-11-21T16:57:07.746201Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"tokenize_data = data.map(preprocess_data, batched = True, remove_columns=['document', 'summary'])","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["1155d59c55414b8eb319b8359de0cb51","439edcd111c74f4e8b023aad54ff614c","f662b47242024f55ab82c83e40cd44a8","1b6ed7ecce8a410fb123348716e325bd","edd0d9b6f6b742b1ba86e9f8d0d6222f","c43e6f76260b4decad996a2ca3198102","f23550c830464f888aec19a60622ce3d","94b27a449be04eaeb84605961610ddb1","7a09725f31584bef97bba6f29856b82f","bf7750858e074552a6efcf646cd13ae7","341a7cd4f32449188c714c82c29f27c2"]},"id":"rygqQ1Gkn_qu","outputId":"104baaa5-a3db-4e0a-b7c4-f99882c753fe","execution":{"iopub.status.busy":"2022-11-21T16:57:07.748676Z","iopub.execute_input":"2022-11-21T16:57:07.749257Z","iopub.status.idle":"2022-11-21T17:03:19.594634Z","shell.execute_reply.started":"2022-11-21T16:57:07.749220Z","shell.execute_reply":"2022-11-21T17:03:19.593705Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/45 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7be5a569937241c0b9f4292f64125302"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/6 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5a58c859fd14fa4b4cf6631b54263ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/6 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc3a9b5f491343e697e7a82460f9b54f"}},"metadata":{}}]},{"cell_type":"markdown","source":"## If memory problems\n\n- sample data to smaller sizes","metadata":{"id":"AvMOVIBiMpOo"}},{"cell_type":"code","source":"#sample the data\ntrain_sample = tokenize_data['train'].shuffle(seed=123).select(range(1000))\nvalidation_sample = tokenize_data['validation'].shuffle(seed=123).select(range(500))\ntest_sample = tokenize_data['test'].shuffle(seed=123).select(range(200))","metadata":{"id":"VWACCTpoGu8b","colab":{"base_uri":"https://localhost:8080/"},"outputId":"30e8272f-f70c-4ff8-9e4a-82d5ef250c2a","execution":{"iopub.status.busy":"2022-11-21T17:03:19.596327Z","iopub.execute_input":"2022-11-21T17:03:19.596733Z","iopub.status.idle":"2022-11-21T17:03:19.638930Z","shell.execute_reply.started":"2022-11-21T17:03:19.596685Z","shell.execute_reply":"2022-11-21T17:03:19.637925Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"tokenize_data['train'] = train_sample\ntokenize_data['validation'] = validation_sample\ntokenize_data['test'] = test_sample","metadata":{"id":"2tKiNnNUHBS6","execution":{"iopub.status.busy":"2022-11-21T17:03:19.640495Z","iopub.execute_input":"2022-11-21T17:03:19.640886Z","iopub.status.idle":"2022-11-21T17:03:19.645848Z","shell.execute_reply.started":"2022-11-21T17:03:19.640849Z","shell.execute_reply":"2022-11-21T17:03:19.644622Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"tokenize_data","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c4TZUupJHFWY","outputId":"01035117-8b56-480f-ec55-75142835b6c6","execution":{"iopub.status.busy":"2022-11-21T17:03:19.650298Z","iopub.execute_input":"2022-11-21T17:03:19.650681Z","iopub.status.idle":"2022-11-21T17:03:19.659215Z","shell.execute_reply.started":"2022-11-21T17:03:19.650621Z","shell.execute_reply":"2022-11-21T17:03:19.658155Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 1000\n    })\n    validation: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 500\n    })\n    test: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 200\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"## Training process","metadata":{"id":"1AYj3_LNL2mk"}},{"cell_type":"code","source":"#load model\nmodel = transformers.AutoModelForSeq2SeqLM.from_pretrained(model_checkpoints)","metadata":{"id":"A3bEO3dOpCT8","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["01315fd3d21d40f694a77c1292d5c48d","6d4d6b64f5a04621b2eb89fed98bb24d","8056e2ea2a7c42ef873aa8c028b696d3","43686ff3741c4fc8ab51a8ad2fe4664d","bfe627cda8d84d70865f40b8e043289b","bdb01bd649024ef9aef1ad6c716fcad4","552cebef4aab4cf29fac95a1ef7910d2","a09d4e3213304039994ed974314044bb","135737bcc62f438d9688be0e885ac291","1fd7cd00c9df4e67b18365d3df3eaf0d","b2438fa7aa154da689234264304e3686"]},"outputId":"83360f74-4dc4-4409-9343-a6f8562d3a4e","execution":{"iopub.status.busy":"2022-11-21T17:03:19.660608Z","iopub.execute_input":"2022-11-21T17:03:19.661203Z","iopub.status.idle":"2022-11-21T17:04:41.497172Z","shell.execute_reply.started":"2022-11-21T17:03:19.661138Z","shell.execute_reply":"2022-11-21T17:04:41.495894Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.51G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6728904ee8ec435098bd3d0061e1c359"}},"metadata":{}}]},{"cell_type":"markdown","source":"Depending on computing power, batch size can go as low as 1 if necessary","metadata":{"id":"bo6DGtCZL_Wb"}},{"cell_type":"code","source":"batch_size = 1","metadata":{"id":"mFoZ3uwUpCX7","execution":{"iopub.status.busy":"2022-11-21T17:04:41.502244Z","iopub.execute_input":"2022-11-21T17:04:41.504497Z","iopub.status.idle":"2022-11-21T17:04:41.510817Z","shell.execute_reply.started":"2022-11-21T17:04:41.504455Z","shell.execute_reply":"2022-11-21T17:04:41.509832Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#collator to create batches. It preprocess data with the given tokenizer\ncollator = transformers.DataCollatorForSeq2Seq(tokenizer, model=model)","metadata":{"id":"7s8_pdYopCbU","execution":{"iopub.status.busy":"2022-11-21T17:04:41.515423Z","iopub.execute_input":"2022-11-21T17:04:41.518154Z","iopub.status.idle":"2022-11-21T17:04:45.447747Z","shell.execute_reply.started":"2022-11-21T17:04:41.518117Z","shell.execute_reply":"2022-11-21T17:04:45.446775Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#####################\n# metrics\n# compute rouge for evaluation \n#####################\n\ndef compute_rouge(pred):\n  predictions, labels = pred\n  #decode the predictions\n  decode_predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n  #decode labels\n  decode_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n  #compute results\n  res = metric.compute(predictions=decode_predictions, references=decode_labels, use_stemmer=True)\n  #get %\n  res = {key: value.mid.fmeasure * 100 for key, value in res.items()}\n\n  pred_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n  res['gen_len'] = np.mean(pred_lens)\n\n  return {k: round(v, 4) for k, v in res.items()}","metadata":{"id":"k4mwnHjvpCeT","execution":{"iopub.status.busy":"2022-11-21T17:04:45.449189Z","iopub.execute_input":"2022-11-21T17:04:45.449581Z","iopub.status.idle":"2022-11-21T17:04:45.459986Z","shell.execute_reply.started":"2022-11-21T17:04:45.449545Z","shell.execute_reply":"2022-11-21T17:04:45.458982Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"args = transformers.Seq2SeqTrainingArguments(\n    'conversation-summ',\n    evaluation_strategy='epoch',\n    learning_rate=2e-5,\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size= 1,\n    gradient_accumulation_steps=2,\n    weight_decay=0.01,\n    save_total_limit=2,\n    num_train_epochs=10,\n    predict_with_generate=True,\n    eval_accumulation_steps=1,\n    fp16=True\n    )\n#only CUDA available -> fp16=True","metadata":{"id":"hNGxpixQqUQM","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d911d29c-3d17-44be-82e5-bff383d7c3a5","execution":{"iopub.status.busy":"2022-11-21T17:04:45.463144Z","iopub.execute_input":"2022-11-21T17:04:45.463422Z","iopub.status.idle":"2022-11-21T17:04:45.556138Z","shell.execute_reply.started":"2022-11-21T17:04:45.463384Z","shell.execute_reply":"2022-11-21T17:04:45.555240Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"trainer = transformers.Seq2SeqTrainer(\n    model, \n    args,\n    train_dataset=tokenize_data['train'],\n    eval_dataset=tokenize_data['validation'],\n    data_collator=collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_rouge\n)","metadata":{"id":"TN4P1UsjqUTq","colab":{"base_uri":"https://localhost:8080/"},"outputId":"59eeb80a-0b3c-4ac9-f0fe-4225db16c0b0","execution":{"iopub.status.busy":"2022-11-21T17:04:45.557430Z","iopub.execute_input":"2022-11-21T17:04:45.557794Z","iopub.status.idle":"2022-11-21T17:04:50.318852Z","shell.execute_reply.started":"2022-11-21T17:04:45.557753Z","shell.execute_reply":"2022-11-21T17:04:50.317882Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"Using cuda_amp half precision backend\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"id":"T_tX926lqUXS","colab":{"base_uri":"https://localhost:8080/","height":606},"outputId":"45526754-b686-4142-9db5-e6a076520916","execution":{"iopub.status.busy":"2022-11-21T17:04:50.320285Z","iopub.execute_input":"2022-11-21T17:04:50.321306Z","iopub.status.idle":"2022-11-21T19:13:15.879947Z","shell.execute_reply.started":"2022-11-21T17:04:50.321264Z","shell.execute_reply":"2022-11-21T19:13:15.878965Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n***** Running training *****\n  Num examples = 1000\n  Num Epochs = 10\n  Instantaneous batch size per device = 1\n  Total train batch size (w. parallel, distributed & accumulation) = 2\n  Gradient Accumulation steps = 2\n  Total optimization steps = 5000\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.13.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.12.21"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20221121_171815-o0kij2y6</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href=\"https://wandb.ai/safasfsa/huggingface/runs/o0kij2y6\" target=\"_blank\">conversation-summ</a></strong> to <a href=\"https://wandb.ai/safasfsa/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5000' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5000/5000 1:54:40, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge1</th>\n      <th>Rouge2</th>\n      <th>Rougel</th>\n      <th>Rougelsum</th>\n      <th>Gen Len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>2.543800</td>\n      <td>2.369417</td>\n      <td>33.615200</td>\n      <td>12.164400</td>\n      <td>20.592400</td>\n      <td>20.607000</td>\n      <td>61.966000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.897400</td>\n      <td>2.393723</td>\n      <td>34.131300</td>\n      <td>12.016700</td>\n      <td>20.645100</td>\n      <td>20.626400</td>\n      <td>61.972000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.430100</td>\n      <td>2.533672</td>\n      <td>33.408700</td>\n      <td>11.591400</td>\n      <td>20.324300</td>\n      <td>20.292000</td>\n      <td>62.000000</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.059600</td>\n      <td>2.789590</td>\n      <td>32.868600</td>\n      <td>11.105000</td>\n      <td>19.953800</td>\n      <td>19.938600</td>\n      <td>62.000000</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.778700</td>\n      <td>3.033906</td>\n      <td>33.252000</td>\n      <td>11.292800</td>\n      <td>20.106200</td>\n      <td>20.082900</td>\n      <td>62.000000</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.559800</td>\n      <td>3.272082</td>\n      <td>32.898200</td>\n      <td>10.932900</td>\n      <td>19.651400</td>\n      <td>19.623700</td>\n      <td>61.982000</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.407300</td>\n      <td>3.484862</td>\n      <td>32.860500</td>\n      <td>10.553300</td>\n      <td>19.498800</td>\n      <td>19.498900</td>\n      <td>61.992000</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.303200</td>\n      <td>3.679194</td>\n      <td>33.067300</td>\n      <td>10.946800</td>\n      <td>19.750300</td>\n      <td>19.746000</td>\n      <td>62.000000</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.235900</td>\n      <td>3.756907</td>\n      <td>32.722900</td>\n      <td>10.674900</td>\n      <td>19.551100</td>\n      <td>19.564700</td>\n      <td>61.972000</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.193700</td>\n      <td>3.820121</td>\n      <td>32.960200</td>\n      <td>10.777500</td>\n      <td>19.825300</td>\n      <td>19.824200</td>\n      <td>62.000000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Saving model checkpoint to conversation-summ/checkpoint-500\nConfiguration saved in conversation-summ/checkpoint-500/config.json\nModel weights saved in conversation-summ/checkpoint-500/pytorch_model.bin\ntokenizer config file saved in conversation-summ/checkpoint-500/tokenizer_config.json\nSpecial tokens file saved in conversation-summ/checkpoint-500/special_tokens_map.json\n***** Running Evaluation *****\n  Num examples = 500\n  Batch size = 1\nSaving model checkpoint to conversation-summ/checkpoint-1000\nConfiguration saved in conversation-summ/checkpoint-1000/config.json\nModel weights saved in conversation-summ/checkpoint-1000/pytorch_model.bin\ntokenizer config file saved in conversation-summ/checkpoint-1000/tokenizer_config.json\nSpecial tokens file saved in conversation-summ/checkpoint-1000/special_tokens_map.json\n***** Running Evaluation *****\n  Num examples = 500\n  Batch size = 1\nSaving model checkpoint to conversation-summ/checkpoint-1500\nConfiguration saved in conversation-summ/checkpoint-1500/config.json\nModel weights saved in conversation-summ/checkpoint-1500/pytorch_model.bin\ntokenizer config file saved in conversation-summ/checkpoint-1500/tokenizer_config.json\nSpecial tokens file saved in conversation-summ/checkpoint-1500/special_tokens_map.json\nDeleting older checkpoint [conversation-summ/checkpoint-500] due to args.save_total_limit\n***** Running Evaluation *****\n  Num examples = 500\n  Batch size = 1\nSaving model checkpoint to conversation-summ/checkpoint-2000\nConfiguration saved in conversation-summ/checkpoint-2000/config.json\nModel weights saved in conversation-summ/checkpoint-2000/pytorch_model.bin\ntokenizer config file saved in conversation-summ/checkpoint-2000/tokenizer_config.json\nSpecial tokens file saved in conversation-summ/checkpoint-2000/special_tokens_map.json\nDeleting older checkpoint [conversation-summ/checkpoint-1000] due to args.save_total_limit\n***** Running Evaluation *****\n  Num examples = 500\n  Batch size = 1\nSaving model checkpoint to conversation-summ/checkpoint-2500\nConfiguration saved in conversation-summ/checkpoint-2500/config.json\nModel weights saved in conversation-summ/checkpoint-2500/pytorch_model.bin\ntokenizer config file saved in conversation-summ/checkpoint-2500/tokenizer_config.json\nSpecial tokens file saved in conversation-summ/checkpoint-2500/special_tokens_map.json\nDeleting older checkpoint [conversation-summ/checkpoint-1500] due to args.save_total_limit\n***** Running Evaluation *****\n  Num examples = 500\n  Batch size = 1\nSaving model checkpoint to conversation-summ/checkpoint-3000\nConfiguration saved in conversation-summ/checkpoint-3000/config.json\nModel weights saved in conversation-summ/checkpoint-3000/pytorch_model.bin\ntokenizer config file saved in conversation-summ/checkpoint-3000/tokenizer_config.json\nSpecial tokens file saved in conversation-summ/checkpoint-3000/special_tokens_map.json\nDeleting older checkpoint [conversation-summ/checkpoint-2000] due to args.save_total_limit\n***** Running Evaluation *****\n  Num examples = 500\n  Batch size = 1\nSaving model checkpoint to conversation-summ/checkpoint-3500\nConfiguration saved in conversation-summ/checkpoint-3500/config.json\nModel weights saved in conversation-summ/checkpoint-3500/pytorch_model.bin\ntokenizer config file saved in conversation-summ/checkpoint-3500/tokenizer_config.json\nSpecial tokens file saved in conversation-summ/checkpoint-3500/special_tokens_map.json\nDeleting older checkpoint [conversation-summ/checkpoint-2500] due to args.save_total_limit\n***** Running Evaluation *****\n  Num examples = 500\n  Batch size = 1\nSaving model checkpoint to conversation-summ/checkpoint-4000\nConfiguration saved in conversation-summ/checkpoint-4000/config.json\nModel weights saved in conversation-summ/checkpoint-4000/pytorch_model.bin\ntokenizer config file saved in conversation-summ/checkpoint-4000/tokenizer_config.json\nSpecial tokens file saved in conversation-summ/checkpoint-4000/special_tokens_map.json\nDeleting older checkpoint [conversation-summ/checkpoint-3000] due to args.save_total_limit\n***** Running Evaluation *****\n  Num examples = 500\n  Batch size = 1\nSaving model checkpoint to conversation-summ/checkpoint-4500\nConfiguration saved in conversation-summ/checkpoint-4500/config.json\nModel weights saved in conversation-summ/checkpoint-4500/pytorch_model.bin\ntokenizer config file saved in conversation-summ/checkpoint-4500/tokenizer_config.json\nSpecial tokens file saved in conversation-summ/checkpoint-4500/special_tokens_map.json\nDeleting older checkpoint [conversation-summ/checkpoint-3500] due to args.save_total_limit\n***** Running Evaluation *****\n  Num examples = 500\n  Batch size = 1\nSaving model checkpoint to conversation-summ/checkpoint-5000\nConfiguration saved in conversation-summ/checkpoint-5000/config.json\nModel weights saved in conversation-summ/checkpoint-5000/pytorch_model.bin\ntokenizer config file saved in conversation-summ/checkpoint-5000/tokenizer_config.json\nSpecial tokens file saved in conversation-summ/checkpoint-5000/special_tokens_map.json\nDeleting older checkpoint [conversation-summ/checkpoint-4000] due to args.save_total_limit\n***** Running Evaluation *****\n  Num examples = 500\n  Batch size = 1\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=5000, training_loss=0.9409502334594727, metrics={'train_runtime': 7705.5192, 'train_samples_per_second': 1.298, 'train_steps_per_second': 0.649, 'total_flos': 1.083552301056e+16, 'train_loss': 0.9409502334594727, 'epoch': 10.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"## Testing the fine tuned model","metadata":{"id":"n8_tIe-qMUUu"}},{"cell_type":"code","source":"conversation = \"\"\"\nRann: Hey Harry, how have you been? Long time no see!\nHarry: Hey! What a surprise! \nHarry: Yes, you are right, we haven’t seen each other in a long time. How have you been?\nRann: There is an important campaign next week which is keeping me busy otherwise rest is going good in my life. \nRann: How about you?\nHarry: Oh! I just finished a meeting with a very important client of mine and now I finally have some free time. I feel relieved that I’m done with it.\nRann: Good for you then. Hey! Let’s make a plan and catch up with each other after next week. \nRann: What do you say?\nHarry: Sure, why not? Give me a call when you are done with your project.\nRann: Sure, then. \nRann: Bye, take care.\nHarry: Bye buddy.\n\"\"\"","metadata":{"id":"L7dflq_tqUeP","execution":{"iopub.status.busy":"2022-11-21T19:13:15.883924Z","iopub.execute_input":"2022-11-21T19:13:15.886809Z","iopub.status.idle":"2022-11-21T19:13:15.895575Z","shell.execute_reply.started":"2022-11-21T19:13:15.886770Z","shell.execute_reply":"2022-11-21T19:13:15.894444Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"model_inputs = tokenizer(conversation,  max_length=max_input, padding='max_length', truncation=True)","metadata":{"id":"BTXf-OY6WrSE","execution":{"iopub.status.busy":"2022-11-21T19:13:15.897105Z","iopub.execute_input":"2022-11-21T19:13:15.897428Z","iopub.status.idle":"2022-11-21T19:13:15.914153Z","shell.execute_reply.started":"2022-11-21T19:13:15.897393Z","shell.execute_reply":"2022-11-21T19:13:15.913221Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"model_inputs","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rSa7fZwjYWAr","outputId":"df0b2d2e-a2b7-4042-8e47-6c4d02c7a12e","execution":{"iopub.status.busy":"2022-11-21T19:13:15.915956Z","iopub.execute_input":"2022-11-21T19:13:15.916279Z","iopub.status.idle":"2022-11-21T19:13:15.925414Z","shell.execute_reply.started":"2022-11-21T19:13:15.916244Z","shell.execute_reply":"2022-11-21T19:13:15.924393Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [0, 50118, 500, 2279, 35, 11468, 3268, 6, 141, 33, 47, 57, 116, 2597, 86, 117, 192, 328, 50118, 29345, 35, 11468, 328, 653, 10, 2755, 328, 1437, 50118, 29345, 35, 3216, 6, 47, 32, 235, 6, 52, 2220, 17, 27, 90, 450, 349, 97, 11, 10, 251, 86, 4, 1336, 33, 47, 57, 116, 50118, 500, 2279, 35, 345, 16, 41, 505, 637, 220, 186, 61, 16, 2396, 162, 3610, 3680, 1079, 16, 164, 205, 11, 127, 301, 4, 1437, 50118, 500, 2279, 35, 1336, 59, 47, 116, 50118, 29345, 35, 5534, 328, 38, 95, 1550, 10, 529, 19, 10, 182, 505, 3653, 9, 4318, 8, 122, 38, 1747, 33, 103, 481, 86, 4, 38, 619, 15126, 14, 38, 17, 27, 119, 626, 19, 24, 4, 50118, 500, 2279, 35, 2497, 13, 47, 172, 4, 11468, 328, 2780, 17, 27, 29, 146, 10, 563, 8, 2916, 62, 19, 349, 97, 71, 220, 186, 4, 1437, 50118, 500, 2279, 35, 653, 109, 47, 224, 116, 50118, 29345, 35, 9136, 6, 596, 45, 116, 12192, 162, 10, 486, 77, 47, 32, 626, 19, 110, 695, 4, 50118, 500, 2279, 35, 9136, 6, 172, 4, 1437, 50118, 500, 2279, 35, 36255, 6, 185, 575, 4, 50118, 29345, 35, 36255, 23279, 4, 50118, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"},"metadata":{}}]},{"cell_type":"code","source":"raw_pred, _, _ = trainer.predict([model_inputs])","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":89},"id":"BLC69SXQYB_a","outputId":"5e889481-c028-465f-d414-b6026aa60f9a","execution":{"iopub.status.busy":"2022-11-21T19:13:15.927181Z","iopub.execute_input":"2022-11-21T19:13:15.927877Z","iopub.status.idle":"2022-11-21T19:13:16.871759Z","shell.execute_reply.started":"2022-11-21T19:13:15.927841Z","shell.execute_reply":"2022-11-21T19:13:16.870867Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"***** Running Prediction *****\n  Num examples = 1\n  Batch size = 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1/1 : < :]\n    </div>\n    "},"metadata":{}}]},{"cell_type":"code","source":"raw_pred","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IL8Y1QFGYi9y","outputId":"4c0ea350-9473-42ef-8e57-c3fb275d8794","execution":{"iopub.status.busy":"2022-11-21T19:13:16.873266Z","iopub.execute_input":"2022-11-21T19:13:16.873633Z","iopub.status.idle":"2022-11-21T19:13:16.882551Z","shell.execute_reply.started":"2022-11-21T19:13:16.873596Z","shell.execute_reply":"2022-11-21T19:13:16.881547Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"array([[    2,     0,     0,     0,  2383,   572,    10,   251,  5171,\n            9,    55,    87,    10,   353,     6,    41,   470,  9716,\n        17065,    11,     5,  2367,   953,  2312,     7,  1349,   159,\n           39,   793, 23279,    11,   188,  3324,     8,  2755,   123,\n           19,    10,  1028,   486,     4,  2595,     5, 12400,     6,\n            5,  9716,     6,  2006,   129,    25,   248,  2279,     6,\n         7173,     5,  1028,    71,  3357,   184,    71,     2]])"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.decode(raw_pred[0])","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"jAP-2KG7YmDS","outputId":"233ad6ac-cc09-4c44-8e79-c7bc55a875f7","execution":{"iopub.status.busy":"2022-11-21T19:13:16.884157Z","iopub.execute_input":"2022-11-21T19:13:16.884781Z","iopub.status.idle":"2022-11-21T19:13:16.892791Z","shell.execute_reply.started":"2022-11-21T19:13:16.884742Z","shell.execute_reply":"2022-11-21T19:13:16.891776Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"'</s><s><s><s>– After a long absence of more than a month, an American soldier stationed in the Middle East managed to track down his old buddy in New Zealand and surprise him with a phone call. Per the Telegraph, the soldier, identified only as Rann, answered the phone after returning home after</s>'"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.decode(raw_pred[0])","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"wYAcNcw-_8L9","outputId":"1fd3ae11-76b2-4c3a-b076-3f72cd1b169d","execution":{"iopub.status.busy":"2022-11-21T19:13:16.894229Z","iopub.execute_input":"2022-11-21T19:13:16.894923Z","iopub.status.idle":"2022-11-21T19:13:16.905279Z","shell.execute_reply.started":"2022-11-21T19:13:16.894887Z","shell.execute_reply":"2022-11-21T19:13:16.904317Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"'</s><s><s><s>– After a long absence of more than a month, an American soldier stationed in the Middle East managed to track down his old buddy in New Zealand and surprise him with a phone call. Per the Telegraph, the soldier, identified only as Rann, answered the phone after returning home after</s>'"},"metadata":{}}]}]}